{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sushma\n",
    "# Erick\n",
    "# Mihir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters and functions required for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "num_adversaries = 100\n",
    "eps = 0.1\n",
    "adversarial_images_log = []\n",
    "\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "# W = tf.Variable(tf.zeros([784, 10]))\n",
    "W = tf.Variable(tf.random_uniform([784, 10]))\n",
    "\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "y_pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "# y_pred = tf.matmul(x, W) + b\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred), reduction_indices=1))\n",
    "# loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "grad_input = tf.gradients(loss, x)[0]\n",
    "\n",
    "# Gradient Descent\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training of the model, testing the model and creation of adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch: 0001 cost= 2.007888049\n",
      "Epoch: 0002 cost= 0.957156892\n",
      "Epoch: 0003 cost= 0.744008170\n",
      "Epoch: 0004 cost= 0.647152671\n",
      "Epoch: 0005 cost= 0.589833768\n",
      "Epoch: 0006 cost= 0.551128170\n",
      "Epoch: 0007 cost= 0.522763877\n",
      "Epoch: 0008 cost= 0.500881828\n",
      "Epoch: 0009 cost= 0.483289561\n",
      "Epoch: 0010 cost= 0.468801075\n",
      "Epoch: 0011 cost= 0.456582990\n",
      "Epoch: 0012 cost= 0.445949509\n",
      "Epoch: 0013 cost= 0.436834550\n",
      "Epoch: 0014 cost= 0.428688067\n",
      "Epoch: 0015 cost= 0.421462887\n",
      "Epoch: 0016 cost= 0.415034226\n",
      "Epoch: 0017 cost= 0.409134357\n",
      "Epoch: 0018 cost= 0.403769310\n",
      "Epoch: 0019 cost= 0.398891721\n",
      "Epoch: 0020 cost= 0.394399105\n",
      "Epoch: 0021 cost= 0.390196257\n",
      "Epoch: 0022 cost= 0.386316099\n",
      "Epoch: 0023 cost= 0.382723886\n",
      "Epoch: 0024 cost= 0.379321654\n",
      "Epoch: 0025 cost= 0.376138643\n",
      "Training Finished!\n",
      "Starting testing\n",
      "Accuracy Testing: 0.8936\n",
      "Accuracy Adversarial: 0.35\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    print(\"Starting training\")\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Training Finished!\")\n",
    "    \n",
    "    print(\"Starting testing\")\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    # Accuracy model\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    #Calculating the accuracy with the testing data.\n",
    "    print (\"Accuracy Testing:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "       \n",
    "    #prediction for one image\n",
    "#     y_prediction = sess.run([y_pred], feed_dict={x:  mnist.test.images,y:  mnist.test.labels})\n",
    "#     print (np.argmax(y_prediction),np.max(y_prediction))\n",
    "#     print (y_prediction)\n",
    "    \n",
    "    #Creation of 100 adversarial examples for logistic regression\n",
    "    grad = sess.run([grad_input], feed_dict={x:  mnist.test.images,y:  mnist.test.labels})\n",
    "    grad = np.array(grad)\n",
    "    grad = grad.reshape(10000,784)\n",
    "\n",
    "    for i in range(num_adversaries):\n",
    "        img_ad = mnist.test.images[i] + eps * np.sign(grad[mnist.test.labels.tolist()[i].index(1.0)]) \n",
    "        adversarial_images_log.append(img_ad)\n",
    "        \n",
    "#     plt.imshow(adversarial_images[i].reshape(28,28), cmap='binary')\n",
    "    \n",
    "    #Prediction for adversial image\n",
    "    y_prediction = sess.run([y_pred], feed_dict={x:  adversarial_images_log,y:  mnist.test.labels[:100]})\n",
    "    \n",
    "    #Calculate the accuracy of the adversarials\n",
    "    print (\"Accuracy Adversarial:\", accuracy.eval({x: adversarial_images_log, y: mnist.test.labels[:100]}))\n",
    "#     print (np.argmax(y_prediction),np.max(y_prediction))\n",
    "#     print (y_prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jasonicarter/MNIST-adversarial-images/blob/master/MNIST-adversarial-images.ipynb\n",
    "image_list = mnist.train.images[0:9]\n",
    "image_list_labels = mnist.train.labels[0:9]\n",
    "\n",
    "# https://matplotlib.org/mpl_toolkits/axes_grid/users/overview.html#imagegrid\n",
    "fig = plt.figure(1, (5., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image = image_list[i].reshape(28,28)\n",
    "    grid[i].imshow(image)\n",
    "    grid[i].set_title('Label: {0}'.format(image_list_labels[i].argmax()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.test.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 Use the adversarial examples of A with model B, and the adversarial examples of B with model A. Do they fool each other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate 60000 new adversarial examples (same size as the training set) and create a new training set containing both the original training data and your adversarial examples. Train both models again with this new training set, and evaluate it with the original MNIST test set. Then answer the following questions:\n",
    "\n",
    "   - Does classification performance improve?\n",
    "\n",
    "   - Is the new model less or more susceptible to adversarial examples?\n",
    "\n",
    "   - Do you think you can use a regularization method in order to make the model less susceptible to adversarial examples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "adversarial_images_ultimate = []\n",
    "num_adversaries_ultimate = len(mnist.train.images)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    print(\"Starting generating the adversarial examples\")\n",
    "    \n",
    "    #Creation of 100 adversarial examples for logistic regression\n",
    "    grad = sess.run([grad_input], feed_dict={x:  mnist.train.images,y:  mnist.train.labels})\n",
    "    grad = np.array(grad)\n",
    "    grad = grad.reshape(len(mnist.train.images),784)\n",
    "\n",
    "    for i in range(num_adversaries_ultimate):\n",
    "        img_ad = mnist.test.images[i] + eps * np.sign(grad[mnist.test.labels.tolist()[i].index(1.0)]) \n",
    "        adversarial_images_log.append(img_ad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
