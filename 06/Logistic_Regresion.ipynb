{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-588cdf1ee33d>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
=======
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 2.302585125\n",
      "Optimization Finished!\n",
      "1\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-76557473714e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdummy2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdummy2_l\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mimg_ad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimg_ad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdummy2_l\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 1\n",
    "eps = 0.007\n",
    "\n",
    "\n",
    "# Single image classification\n",
    "x = tf.placeholder(tf.float32, (None, 784)) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "grad_input = tf.gradients(cost, x)[0]\n",
    "init = tf.global_variables_initializer()\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Image to train\n",
    "    dummy = mnist.train.images[0]\n",
    "    dummy = np.reshape(dummy,(1,784))\n",
    "    dummy_l = mnist.train.labels[0]\n",
    "    dummy_l = dummy_l[np.newaxis,:]\n",
    "    \n",
    "#     print(dummy_l.shape)\n",
    "    \n",
    "    #Image to test\n",
    "    dummy2 = mnist.train.images[0]\n",
    "    dummy2 = dummy2[np.newaxis,:]\n",
    "    dummy2_l = mnist.train.labels[0]\n",
    "    dummy2_l = dummy2_l[np.newaxis,:]\n",
    "        \n",
    "    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "    _, c = sess.run([optimizer, cost], feed_dict={x: dummy,\n",
    "                                                          y: dummy_l})\n",
    "        \n",
    "    print(\"Epoch:\", '%04d' % (1), \"cost=\", \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    grad = sess.run([grad_input], feed_dict={x: dummy,y: dummy_l})\n",
    "    \n",
    "    print(len(grad))\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: dummy2, y: dummy2_l}))\n",
    "    \n",
    "    img_ad = dummy + eps * np.sign(grad[mnist.train.labels.tolist()[0].index(1.0)])\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy.eval({x: img_ad, y: dummy2_l}))\n",
    "#this will get u the gradients of the test images.\n",
    "#Then you have to create adversial images using this gradient\n",
    "# for i in range(100):\n",
    "#     img_ad = mnist.test.images[i] + eps * np.sign(grad[mnist.test.labels.tolist()[i].index(1.0)])\n",
    "# adversarial_images.append(img_ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.labels.tolist()[0].index(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
>>>>>>> upstream/master
    "learning_rate = 0.01\n",
    "training_epochs = 25\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "\n",
    "\n",
    "# tf Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition => 10 classes\n",
    "\n",
    "# Set model weights\n",
    "# W = tf.Variable(tf.zeros([784, 10]))\n",
    "W = tf.Variable(tf.random_uniform([784, 10]))\n",
    "\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# Construct model\n",
    "y_pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax\n",
    "# y_pred = tf.matmul(x, W) + b\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred), reduction_indices=1))\n",
    "# loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "grad_input = tf.gradients(loss, x)[0]\n",
    "\n",
    "# Gradient Descent\n",
<<<<<<< HEAD
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
=======
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "deriv = tf.gradients(cost, x)[0]\n",
    "image_adv = tf.stop_gradient(x - tf.multiply(2.5,tf.sign(deriv)*learning_rate))\n",
    "image_adv = tf.clip_by_value(image_adv, 0, 1)\n",
>>>>>>> upstream/master
    "\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
<<<<<<< HEAD
    "\n"
=======
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    #Image to train\n",
    "    dummy = mnist.train.images[0]\n",
    "    dummy = np.reshape(dummy,(1,784))\n",
    "    dummy_l = mnist.train.labels[0]\n",
    "    dummy_l = dummy_l[np.newaxis,:]\n",
    "    \n",
    "    #Image to test\n",
    "    dummy2 = mnist.train.images[0]\n",
    "    dummy2 = dummy2[np.newaxis,:]\n",
    "    dummy2_l = mnist.train.labels[0]\n",
    "    dummy2_l = dummy2_l[np.newaxis,:]\n",
    "        \n",
    "    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "    _, c = sess.run([optimizer, cost], feed_dict={x: dummy,\n",
    "                                                          y: dummy_l})\n",
    "        \n",
    "    print(\"Epoch:\", '%04d' % (1), \"cost=\", \"{:.9f}\".format(c))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "#     print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: dummy2, y: dummy2_l}))\n",
    "    \n",
    "    #Computes gradients, I think or hope!\n",
    "    dydx = sess.run(deriv,  feed_dict = {x: dummy, y:dummy_l}) # can't seem to access 'deriv' w/o running this\n",
    "#     _ = sess.run([grad_input, cost], feed_dict={x: dummy,\n",
    "#                                                           y: dummy_l})\n",
    "    x_adv = sess.run(image_adv, {x: dummy2, y:dummy_l})\n",
    "    x_adv = x_adv.reshape(1,784)\n",
    "    print(\"Accuracy:\", accuracy.eval({x: x_adv, y: dummy_l}))\n",
    "    \n",
    "    plt.imshow(x_adv.reshape((28,28)), cmap='Greys')\n",
    "    "
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 1.927479186\n",
      "Epoch: 0002 cost= 0.985616101\n",
      "Epoch: 0003 cost= 0.768157658\n",
      "Epoch: 0004 cost= 0.665464267\n",
      "Epoch: 0005 cost= 0.603922852\n",
      "Epoch: 0006 cost= 0.562225222\n",
      "Epoch: 0007 cost= 0.531758446\n",
      "Epoch: 0008 cost= 0.508280439\n",
      "Epoch: 0009 cost= 0.489533124\n",
      "Epoch: 0010 cost= 0.474076727\n",
      "Epoch: 0011 cost= 0.461075474\n",
      "Epoch: 0012 cost= 0.450054493\n",
      "Epoch: 0013 cost= 0.440441170\n",
      "Epoch: 0014 cost= 0.431911310\n",
      "Epoch: 0015 cost= 0.424440937\n",
      "Epoch: 0016 cost= 0.417667174\n",
      "Epoch: 0017 cost= 0.411621388\n",
      "Epoch: 0018 cost= 0.406088345\n",
      "Epoch: 0019 cost= 0.401081371\n",
      "Epoch: 0020 cost= 0.396404868\n",
      "Epoch: 0021 cost= 0.392133246\n",
      "Epoch: 0022 cost= 0.388137289\n",
      "Epoch: 0023 cost= 0.384462404\n",
      "Epoch: 0024 cost= 0.381000551\n",
      "Epoch: 0025 cost= 0.377785307\n",
      "Optimization Finished!\n",
      "Accuracy: 0.8991\n",
      "Adversarial Accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            _, c = sess.run([optimizer, loss], feed_dict={x: batch_xs,\n",
    "                                                          y: batch_ys})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    print (\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print (\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "       \n",
    "    #prediction for one image\n",
    "    y_prediction = sess.run([y_pred], feed_dict={x:  mnist.test.images,y:  mnist.test.labels})\n",
    "#     print (np.argmax(y_prediction),np.max(y_prediction))\n",
    "#     print (y_prediction)\n",
    "    \n",
    "    #adversial \n",
    "    grad = sess.run([grad_input], feed_dict={x:  mnist.test.images,y:  mnist.test.labels})\n",
    "    grad = np.array(grad)\n",
    "    grad = grad.reshape(10000,784)\n",
    "    eps = 0.1\n",
    "    adversarial_images = []\n",
    "\n",
    "    for i in range(100):\n",
    "        img_ad = mnist.test.images[i] + eps * np.sign(grad[mnist.test.labels.tolist()[i].index(1.0)]) \n",
    "        adversarial_images.append(img_ad)\n",
    "        \n",
    "    plt.imshow(adversarial_images[i].reshape(28,28), cmap='binary')\n",
    "    \n",
    "    #prediction for adversial image\n",
    "    y_prediction = sess.run([y_pred], feed_dict={x:  adversarial_images,y:  mnist.test.labels[:100]})\n",
    "    print (\"Adversarial Accuracy:\", accuracy.eval({x: adversarial_images, y: mnist.test.labels[:100]}))\n",
    "#     print (np.argmax(y_prediction),np.max(y_prediction))\n",
    "#     print (y_prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jasonicarter/MNIST-adversarial-images/blob/master/MNIST-adversarial-images.ipynb\n",
    "image_list = mnist.train.images[0:9]\n",
    "image_list_labels = mnist.train.labels[0:9]\n",
    "\n",
    "# https://matplotlib.org/mpl_toolkits/axes_grid/users/overview.html#imagegrid\n",
    "fig = plt.figure(1, (5., 5.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(3, 3),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for i in range(len(image_list)):\n",
    "    image = image_list[i].reshape(28,28)\n",
    "    grid[i].imshow(image)\n",
    "    grid[i].set_title('Label: {0}'.format(image_list_labels[i].argmax()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
